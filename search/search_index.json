{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"2019-snakemake-byok8s \u00b6 Overview \u00b6 This is an example of a Snakemake workflow that: is a command line utility called byok8s is bundled as an installable Python package is designed to run on a Kubernetes (k8s) cluster can be tested with Travis CI (and/or locally) using minikube How is byok8s invoked? \u00b6 Snakemake functionality is provided through a command line tool called byok8s , so that it allows you to do this (also see the Quickstart Guide ). # Install byok8s python setup.py build install # Create virtual k8s cluster minikube start # Run the workflow on the k8s cluster cd /path/to/workflow/ byok8s my-workflowfile my-paramsfile --s3-bucket=my-bucket # Clean up the virtual k8s cluster minikube stop How does byok8s work? \u00b6 The command line utility requires the user to provide three inputs: A snakemake workflow, via a Snakefile A workflow configuration file (JSON) A workflow parameters file (JSON) Additionally, the user must have a Kubernetes cluster running. (The approach is for the user to bring their own Kubernetes cluster to the table - hence byok8s = Bring Your Own Kubernetes). The workflow config file specifies which workflow targets and input files to use. The workflow parameters file specifies which parameters to use for the workflow steps. Why S3 Buckets? \u00b6 AWS credentials and an S3 bucket is required to run workflows because of restrictions on file I/O on nodes in a kubernes cluster. The Snakemake workflows use AWS S3 buckets as remote providers for the Kubernetes nodes, but this can be modified to any others that Snakemake supports. AWS credentials are set with the two environment variables: AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY These are passed into the Kubernetes cluster by byok8s and Snakemake. Kubernetes and Minikube \u00b6 Kubernetes is a technology that utilizes Docker container to orchestrate a cluster of compute nodes. These compute nodes are usually real compute nodes requested and managed via a cloud provider, like AWS or Google Cloud. But the compute nodes can also be virtual, which is where minikube comes in. It creates a kubernetes cluster that is entirely local and virtual, which makes testing easy. See the byok8s Minikube Guide for details about how to use minikube with byok8s. The Travis CI tests also utilize minikube to run test workflows. See byok8s Travis Tests for more information. Cloud Providers \u00b6 For real workflows, your options for kubernetes clusters are cloud providers. We have guides for the following: AWS EKS (Elastic Container Service) GCP GKE (Google Kuberntes Engine) Digital Ocean Kubernetes service Kubernetes + byok8s: In Practice \u00b6 Cloud Provider Kubernetes Service Guide Minikube (on AWS EC2) Minikube byok8s Minikube Guide Google Cloud Platform (GCP) Google Container Engine (GKE) byok8s GCP GKE Guide Amazon Web Services (AWS) Elastic Container Service (EKS) byok8s AWS EKS Guide Digital Ocean (DO) DO Kubernetes (DOK) byok8s DO DOK Guide","title":"Index"},{"location":"#2019-snakemake-byok8s","text":"","title":"2019-snakemake-byok8s"},{"location":"#overview","text":"This is an example of a Snakemake workflow that: is a command line utility called byok8s is bundled as an installable Python package is designed to run on a Kubernetes (k8s) cluster can be tested with Travis CI (and/or locally) using minikube","title":"Overview"},{"location":"#how-is-byok8s-invoked","text":"Snakemake functionality is provided through a command line tool called byok8s , so that it allows you to do this (also see the Quickstart Guide ). # Install byok8s python setup.py build install # Create virtual k8s cluster minikube start # Run the workflow on the k8s cluster cd /path/to/workflow/ byok8s my-workflowfile my-paramsfile --s3-bucket=my-bucket # Clean up the virtual k8s cluster minikube stop","title":"How is byok8s invoked?"},{"location":"#how-does-byok8s-work","text":"The command line utility requires the user to provide three inputs: A snakemake workflow, via a Snakefile A workflow configuration file (JSON) A workflow parameters file (JSON) Additionally, the user must have a Kubernetes cluster running. (The approach is for the user to bring their own Kubernetes cluster to the table - hence byok8s = Bring Your Own Kubernetes). The workflow config file specifies which workflow targets and input files to use. The workflow parameters file specifies which parameters to use for the workflow steps.","title":"How does byok8s work?"},{"location":"#why-s3-buckets","text":"AWS credentials and an S3 bucket is required to run workflows because of restrictions on file I/O on nodes in a kubernes cluster. The Snakemake workflows use AWS S3 buckets as remote providers for the Kubernetes nodes, but this can be modified to any others that Snakemake supports. AWS credentials are set with the two environment variables: AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY These are passed into the Kubernetes cluster by byok8s and Snakemake.","title":"Why S3 Buckets?"},{"location":"#kubernetes-and-minikube","text":"Kubernetes is a technology that utilizes Docker container to orchestrate a cluster of compute nodes. These compute nodes are usually real compute nodes requested and managed via a cloud provider, like AWS or Google Cloud. But the compute nodes can also be virtual, which is where minikube comes in. It creates a kubernetes cluster that is entirely local and virtual, which makes testing easy. See the byok8s Minikube Guide for details about how to use minikube with byok8s. The Travis CI tests also utilize minikube to run test workflows. See byok8s Travis Tests for more information.","title":"Kubernetes and Minikube"},{"location":"#cloud-providers","text":"For real workflows, your options for kubernetes clusters are cloud providers. We have guides for the following: AWS EKS (Elastic Container Service) GCP GKE (Google Kuberntes Engine) Digital Ocean Kubernetes service","title":"Cloud Providers"},{"location":"#kubernetes-byok8s-in-practice","text":"Cloud Provider Kubernetes Service Guide Minikube (on AWS EC2) Minikube byok8s Minikube Guide Google Cloud Platform (GCP) Google Container Engine (GKE) byok8s GCP GKE Guide Amazon Web Services (AWS) Elastic Container Service (EKS) byok8s AWS EKS Guide Digital Ocean (DO) DO Kubernetes (DOK) byok8s DO DOK Guide","title":"Kubernetes + byok8s: In Practice"},{"location":"kubernetes_aws/","text":"Kubernetes on AWS \u00b6 Elastic Container Service \u00b6 Quickstart \u00b6","title":"K8s with AWS"},{"location":"kubernetes_aws/#kubernetes-on-aws","text":"","title":"Kubernetes on AWS"},{"location":"kubernetes_aws/#elastic-container-service","text":"","title":"Elastic Container Service"},{"location":"kubernetes_aws/#quickstart","text":"","title":"Quickstart"},{"location":"kubernetes_dok/","text":"Kubernetes on Digital Ocean \u00b6 Digital Ocean Kubernetes \u00b6 (Use web interface to set up a Kubernetes cluster, then use kubectl to connect with Digital Ocean via Digital Ocean credentials.) Quickstart \u00b6 link","title":"K8s with DigitalOcean"},{"location":"kubernetes_dok/#kubernetes-on-digital-ocean","text":"","title":"Kubernetes on Digital Ocean"},{"location":"kubernetes_dok/#digital-ocean-kubernetes","text":"(Use web interface to set up a Kubernetes cluster, then use kubectl to connect with Digital Ocean via Digital Ocean credentials.)","title":"Digital Ocean Kubernetes"},{"location":"kubernetes_dok/#quickstart","text":"link","title":"Quickstart"},{"location":"kubernetes_gcp/","text":"Kubernetes on Google Cloud Platform \u00b6 Google Container Engine \u00b6 Quickstart \u00b6","title":"K8s with GCP"},{"location":"kubernetes_gcp/#kubernetes-on-google-cloud-platform","text":"","title":"Kubernetes on Google Cloud Platform"},{"location":"kubernetes_gcp/#google-container-engine","text":"","title":"Google Container Engine"},{"location":"kubernetes_gcp/#quickstart","text":"","title":"Quickstart"},{"location":"kubernetes_minikube/","text":"Minikube on AWS EC2 Nodes \u00b6 Quickstart \u00b6","title":"K8s with Minikube"},{"location":"kubernetes_minikube/#minikube-on-aws-ec2-nodes","text":"","title":"Minikube on AWS EC2 Nodes"},{"location":"kubernetes_minikube/#quickstart","text":"","title":"Quickstart"},{"location":"quickstart/","text":"Quickstart \u00b6 This runs through the installation and usage of 2019-snakemake-byok8s . Step 1: Set up Kubernetes cluster with minikube . Step 2: Install byok8s . Step 3: Run the byok8s workflow using the Kubernetes cluster. Step 4: Tear down Kubernetes cluster with minikube . Step 1: Set Up Virtual Kubernetes Cluster \u00b6 For the purposes of the quickstart, we will walk through how to set up a local, virtual Kubernetes cluster using minikube . Start by installing minikube: scripts/install_minikube.sh Once it is installed, you can start up a kubernetes cluster with minikube using the following commands: cd test minikube start NOTE: If you are running on AWS, run this command first minikube config set vm-driver none to set the the vm driver to none and use native Docker to run stuff. If you are running on AWS, the DNS in the minikube kubernetes cluster will not work, so run this command to fix the DNS settings (should be run from the test/ directory): kubectl apply -f fixcoredns.yml kubectl delete --all pods --namespace kube-system Step 2: Install byok8s \u00b6 Start by setting up a python virtual environment, and install the required packages into the virtual environment: pip install -r requirements.txt This installs snakemake and kubernetes Python modules. Now install the byok8s command line tool: python setup.py build install Now you can run: which byok8s and you should see byok8s in your virtual environment's bin/ directory. This command line utility will expect a kubernetes cluster to be set up before it is run. Setting up a kubernetes cluster will create... (fill in more info here)... Snakemake will automatically create the pods in the cluster, so you just need to allocate a kubernetes cluster. Step 3: Run byok8s \u00b6 Now you can run the workflow with the byok8s command. This submits the Snakemake workflow jobs to the Kubernetes cluster that minikube created. You should have your workflow in a Snakefile in the current directory. Use the --snakefile flag if it is named something other than Snakefile . You will also need to specify your AWS credentials via the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables. These are used to to access S3 buckets for file I/O. Finally, you will need to create an S3 bucket for Snakemake to use for file I/O. Pass the name of the bucket using the --s3-bucket flag. Start by exporting these two vars (careful to scrub them from bash history): export AWS_ACCESS_KEY_ID=XXXXX export AWS_SECRET_ACCESS_KEY=XXXXX Run the alpha workflow with blue params: byok8s --s3-bucket=mah-bukkit workflow-alpha params-blue Run the alpha workflow with red params: byok8s --s3-bucket=mah-bukkit workflow-alpha params-red Run the gamma workflow with red params, &c: byok8s --s3-bucket=mah-bukkit workflow-gamma params-red (NOTE: May want to let the user specify input and output directories with flags.) All input files are searched for relative to the working directory. Step 4: Tear Down Kubernetes Cluster \u00b6 The last step once the workflow has been finished, is to tear down the kubernetes cluster. The virtual kubernetes cluster created by minikube can be torn down with the following command: minikube stop","title":"Quickstart"},{"location":"quickstart/#quickstart","text":"This runs through the installation and usage of 2019-snakemake-byok8s . Step 1: Set up Kubernetes cluster with minikube . Step 2: Install byok8s . Step 3: Run the byok8s workflow using the Kubernetes cluster. Step 4: Tear down Kubernetes cluster with minikube .","title":"Quickstart"},{"location":"quickstart/#step-1-set-up-virtual-kubernetes-cluster","text":"For the purposes of the quickstart, we will walk through how to set up a local, virtual Kubernetes cluster using minikube . Start by installing minikube: scripts/install_minikube.sh Once it is installed, you can start up a kubernetes cluster with minikube using the following commands: cd test minikube start NOTE: If you are running on AWS, run this command first minikube config set vm-driver none to set the the vm driver to none and use native Docker to run stuff. If you are running on AWS, the DNS in the minikube kubernetes cluster will not work, so run this command to fix the DNS settings (should be run from the test/ directory): kubectl apply -f fixcoredns.yml kubectl delete --all pods --namespace kube-system","title":"Step 1: Set Up Virtual Kubernetes Cluster"},{"location":"quickstart/#step-2-install-byok8s","text":"Start by setting up a python virtual environment, and install the required packages into the virtual environment: pip install -r requirements.txt This installs snakemake and kubernetes Python modules. Now install the byok8s command line tool: python setup.py build install Now you can run: which byok8s and you should see byok8s in your virtual environment's bin/ directory. This command line utility will expect a kubernetes cluster to be set up before it is run. Setting up a kubernetes cluster will create... (fill in more info here)... Snakemake will automatically create the pods in the cluster, so you just need to allocate a kubernetes cluster.","title":"Step 2: Install byok8s"},{"location":"quickstart/#step-3-run-byok8s","text":"Now you can run the workflow with the byok8s command. This submits the Snakemake workflow jobs to the Kubernetes cluster that minikube created. You should have your workflow in a Snakefile in the current directory. Use the --snakefile flag if it is named something other than Snakefile . You will also need to specify your AWS credentials via the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables. These are used to to access S3 buckets for file I/O. Finally, you will need to create an S3 bucket for Snakemake to use for file I/O. Pass the name of the bucket using the --s3-bucket flag. Start by exporting these two vars (careful to scrub them from bash history): export AWS_ACCESS_KEY_ID=XXXXX export AWS_SECRET_ACCESS_KEY=XXXXX Run the alpha workflow with blue params: byok8s --s3-bucket=mah-bukkit workflow-alpha params-blue Run the alpha workflow with red params: byok8s --s3-bucket=mah-bukkit workflow-alpha params-red Run the gamma workflow with red params, &c: byok8s --s3-bucket=mah-bukkit workflow-gamma params-red (NOTE: May want to let the user specify input and output directories with flags.) All input files are searched for relative to the working directory.","title":"Step 3: Run byok8s"},{"location":"quickstart/#step-4-tear-down-kubernetes-cluster","text":"The last step once the workflow has been finished, is to tear down the kubernetes cluster. The virtual kubernetes cluster created by minikube can be torn down with the following command: minikube stop","title":"Step 4: Tear Down Kubernetes Cluster"},{"location":"travis_tests/","text":"Travis Tests with Minikube \u00b6","title":"Travis Tests"},{"location":"travis_tests/#travis-tests-with-minikube","text":"","title":"Travis Tests with Minikube"}]}